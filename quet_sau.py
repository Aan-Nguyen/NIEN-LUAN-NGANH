import os, sys, json, io, check 
from PIL import Image

# ==============================
# ‚öôÔ∏è C·∫•u h√¨nh c∆° b·∫£n
# ==============================
CHUNK_SIZE = 128 * 1024 * 1024     # 4 MB (th·ª±c ra l√† 128MB theo code g·ªëc)
MAX_BUFFER = 256 * 1024 * 1024    # 64 MB gi·ªØ buffer bi√™n (th·ª±c ra l√† 256MB)
OUTPUT_DIR = "recovered_files"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==============================
# üîç Ch·ªØ k√Ω file (head -> tail)
# ==============================
SIGNATURES = {
    "jpg":  {"head": b"\xFF\xD8", "tail": b"\xFF\xD9", "strategy": "simple", "ext":"jpg"},
    "png":  {"head": b"\x89PNG\r\n\x1a\n", "tail": b"IEND\xAE\x42\x60\x82", "strategy": "simple", "ext":"png"},
    "pdf":  {"head": b"%PDF-", "tail": b"%%EOF", "strategy": "pdf", "ext":"pdf"},
    "webp": {"head": b"RIFF", "tail": None, "strategy":"riff", "ext":"webp"},
    # Office d·∫°ng ZIP
    "docx": {"head": b"PK\x03\x04", "tail": b"PK\x05\x06", "strategy":"zip", "ext":"docx"},
    "xlsx": {"head": b"PK\x03\x04", "tail": b"PK\x05\x06", "strategy":"zip", "ext":"xlsx"},
    "pptx": {"head": b"PK\x03\x04", "tail": b"PK\x05\x06", "strategy":"zip", "ext":"pptx"},
}

ALL_HEADS = [v["head"] for v in SIGNATURES.values() if v.get("head")]

# ==============================
# üß© H√†m ƒë·ªçc an to√†n
# ==============================
def safe_read(f, size):
    try:
        return f.read(size)
    except Exception:
        return b""

# üß† Ki·ªÉm tra h·ª£p l·ªá
def is_valid_image(data, ftype):
    try:
        if ftype == "png":
            if not data.startswith(b"\x89PNG") or b"IHDR" not in data[:64]:
                return False
            if b"IEND" not in data:
                return False
        elif ftype == "jpg":
            img = Image.open(io.BytesIO(data))
            img.verify()
        return True
    except Exception:
        return False

def is_valid_pdf(data):
    return data.startswith(b"%PDF-") and b"%%EOF" in data[-2048:]

def is_valid_webp(data):
    if len(data) < 12:
        return False
    if not data.startswith(b"RIFF") or data[8:12] != b"WEBP":
        return False
    return True

def is_valid_office_zip(data, target):
    if not data.startswith(b"PK\x03\x04"):
        return False
    snippet = data[:4096]
    if target == "docx" and b"word/" in snippet:
        return True
    if target == "xlsx" and b"xl/" in snippet:
        return True
    if target == "pptx" and b"ppt/" in snippet:
        return True
    return False

# üìè H√†m t√¨m tail
def find_tail_simple(buf, head_idx, tail):
    idx = buf.find(tail, head_idx + len(tail))
    return None if idx == -1 else idx + len(tail)

def find_tail_pdf(buf, head_idx, tail=None):
    idx = buf.find(b"%%EOF", head_idx)
    return None if idx == -1 else idx + len(b"%%EOF")

def find_tail_riff(buf, head_idx, tail=None):
    if len(buf) < head_idx + 12:
        return None
    size_field = int.from_bytes(buf[head_idx+4:head_idx+8], "little")
    end = head_idx + 8 + size_field
    return end if end < len(buf) else None

def find_tail_zip(buf, head_idx, tail=None):
    eocd = buf.find(b"PK\x05\x06", head_idx)
    return None if eocd == -1 else eocd + 22


TAIL_FINDERS = {
    "simple": find_tail_simple,
    "pdf": find_tail_pdf,
    "riff": find_tail_riff,
    "zip": find_tail_zip,
}


def carve_unified(source_path, max_scan_gb):
    print(f"Opening: {source_path}", flush=True)
    print("PROGRESS 0", flush=True)
    
    results = []
    buffer = b""
    
    # [QUAN TR·ªåNG] Bi·∫øn theo d√µi t·ªïng s·ªë byte ƒë√£ ƒë·ªçc t·ª´ file g·ªëc
    total_bytes_read = 0 
    
    max_scan_bytes = max_scan_gb * 1024 * 1024 * 1024
    last_percent = -1

    try:
        with open(source_path, "rb") as f:
            while True:
                # Ki·ªÉm tra gi·ªõi h·∫°n qu√©t
                if total_bytes_read >= max_scan_bytes:
                    break

                # ƒê·ªçc chunk m·ªõi
                chunk = safe_read(f, CHUNK_SIZE)
                if not chunk:
                    break
                
                buffer += chunk
                total_bytes_read += len(chunk)

                # [QUAN TR·ªåNG] T√≠nh offset c·ªßa ƒë·∫ßu buffer hi·ªán t·∫°i
                # Buffer hi·ªán t·∫°i b·∫Øt ƒë·∫ßu t·∫°i v·ªã tr√≠: T·ªïng ƒë√£ ƒë·ªçc - ƒê·ªô d√†i buffer hi·ªán c√≥
                buffer_start_offset = total_bytes_read - len(buffer)

                # Duy·ªát qua c√°c lo·∫°i file c·∫ßn t√¨m
                for key, sig in SIGNATURES.items():
                    search_pos = 0 # V·ªã tr√≠ t√¨m ki·∫øm t∆∞∆°ng ƒë·ªëi trong buffer
                    
                    while True:
                        # T√¨m header
                        start_rel = buffer.find(sig["head"], search_pos)
                        if start_rel == -1:
                            break

                        # [QUAN TR·ªåNG] T√≠nh Offset Tuy·ªát ƒê·ªëi CH√çNH X√ÅC
                        abs_offset = buffer_start_offset + start_rel

                        # T√¨m tail
                        end_rel = TAIL_FINDERS[sig["strategy"]](buffer, start_rel, sig.get("tail"))
                        
                        # N·∫øu kh√¥ng t√¨m th·∫•y tail, ho·∫∑c file qu√° l·ªõn v∆∞·ª£t buffer -> b·ªè qua t·∫°m th·ªùi
                        if end_rel is None:
                            # N·∫øu buffer ƒë√£ qu√° l·ªõn m√† v·∫´n ch∆∞a th·∫•y tail, c√≥ th·ªÉ file l·ªói ho·∫∑c qu√° to
                            # Ta skip header n√†y ƒë·ªÉ tr√°nh v√≤ng l·∫∑p v√¥ t·∫≠n
                            if len(buffer) >= MAX_BUFFER:
                                search_pos = start_rel + 1 
                                continue
                            else:
                                # Ch∆∞a ƒë·ªß d·ªØ li·ªáu, tho√°t v√≤ng l·∫∑p t√¨m ki·∫øm ƒë·ªÉ ƒë·ªçc th√™m chunk m·ªõi
                                break
                        
                        # Tr√≠ch xu·∫•t d·ªØ li·ªáu
                        data = buffer[start_rel:end_rel]

                        # [Logic Ki·ªÉm tra tr√πng l·∫∑p offset n·∫øu c·∫ßn thi·∫øt]
                        # (B·∫°n c√≥ th·ªÉ th√™m logic check seen_ranges ·ªü ƒë√¢y n·∫øu mu·ªën)

                        # X√°c th·ª±c d·ªØ li·ªáu (Validate)
                        ok = False
                        if key in ("jpg", "png"):
                            ok = is_valid_image(data, key)
                        elif key == "pdf":
                            ok = is_valid_pdf(data)
                        elif key == "webp":
                            ok = is_valid_webp(data)
                        elif key in ("docx", "xlsx", "pptx"):
                            ok = is_valid_office_zip(data, key)

                        if ok:
                            # Xu·∫•t file
                            filename = f"{key}_{abs_offset}.{sig['ext']}" # ƒê·∫∑t t√™n theo offset ƒë·ªÉ d·ªÖ debug
                            out_path = os.path.join(OUTPUT_DIR, filename)
                            with open(out_path, "wb") as out:
                                out.write(data)

                            # Check Integrity
                            integrity_str = "N/A"
                            try:
                                integrity_score = check.analyze_file_integrity(out_path)
                                integrity_str = f"{integrity_score:.2f}"
                            except Exception as e:
                                integrity_str = f"Error: {e}"

                            # Ghi k·∫øt qu·∫£
                            entry = {
                                "name": filename,
                                "full_path": os.path.abspath(source_path),
                                "offset": abs_offset, # [CH√çNH X√ÅC]
                                "size": len(data),
                                "type": key,
                                "temp_path": os.path.abspath(out_path),
                                "integrity": integrity_str,
                                "status": "Carved"
                            }
                            entry["Chi ti·∫øt"] = entry.copy()
                            results.append(entry)
                            
                            # C·∫≠p nh·∫≠t v·ªã tr√≠ t√¨m ki·∫øm ti·∫øp theo
                            search_pos = end_rel
                        else:
                            # N·∫øu kh√¥ng valid, t√¨m ti·∫øp t·ª´ ngay sau header
                            search_pos = start_rel + 1

                # [C∆† CH·∫æ TR∆Ø·ª¢T BUFFER - SLIDING WINDOW]
                # Gi·ªØ l·∫°i m·ªôt ph·∫ßn cu·ªëi buffer ƒë·ªÉ n·ªëi v·ªõi chunk sau (ph√≤ng tr∆∞·ªùng h·ª£p file n·∫±m gi·ªØa ranh gi·ªõi 2 chunk)
                # K√≠ch th∆∞·ªõc gi·ªØ l·∫°i n√™n l·ªõn h∆°n k√≠ch th∆∞·ªõc file l·ªõn nh·∫•t k·ª≥ v·ªçng (v√≠ d·ª• 10MB) 
                # ho·∫∑c ƒë∆°n gi·∫£n l√† gi·ªØ l·∫°i m·ªôt ph·∫ßn c·ªßa MAX_BUFFER.
                
                KEEP_SIZE = 10 * 1024 * 1024 # Gi·ªØ l·∫°i 10MB cu·ªëi
                if len(buffer) > KEEP_SIZE:
                     buffer = buffer[-KEEP_SIZE:]
                
                # C·∫≠p nh·∫≠t Progress
                if max_scan_bytes > 0:
                    percent = int((total_bytes_read / max_scan_bytes) * 100)
                    if percent > 100: percent = 100
                    if percent > last_percent:
                        print(f"PROGRESS {percent}", flush=True)
                        last_percent = percent

    except Exception as e:
        print(f"[‚ùå] Error: {e}", flush=True)

    # Xu·∫•t JSON k·∫øt qu·∫£
    output_json = "deleted_files.json"
    with open(output_json, "w", encoding="utf-8") as jf:
        json.dump(results, jf, indent=2, ensure_ascii=False)
    
    print("PROGRESS 100", flush=True)
    print(f"[‚úÖ] Done. Found {len(results)} files.", flush=True)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python quet_sau.py <path> [GB]")
    else:
        drive = sys.argv[1]
        size = float(sys.argv[2]) if len(sys.argv) > 2 else 1
        carve_unified(drive, max_scan_gb=size)